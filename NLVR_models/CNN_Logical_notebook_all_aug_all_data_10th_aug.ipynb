{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cafa9634-e1aa-43c2-a960-7abc2d65e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from utl2 import dataset, ToTensor\n",
    "from cnn_mlp import CNN_MLP\n",
    "from cnn_lstm import CNN_LSTM\n",
    "from resnet18 import Resnet18_MLP\n",
    "from cnn_logical_v1 import CNN_Logical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2668e7a7-6923-4e40-8ba0-cc248efb3162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    model='CNN_Logical'\n",
    "    epochs=400\n",
    "    batch_size=32\n",
    "    seed=12345\n",
    "    dataset = 'iRaven'\n",
    "    device = 0\n",
    "    load_workers = 16\n",
    "    resume = False\n",
    "    path = \"/common/users/pv217/pritish_data\"\n",
    "    save = \"/common/users/pv217/model_checkpoints/full_cnn_logical_all_aug_10aug/\"\n",
    "    img_size = 80\n",
    "    lr = 1e-4\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    epsilon = 1e-8\n",
    "    meta_alpha = 0.0\n",
    "    meta_beta = 0.0\n",
    "    cuda = torch.cuda.is_available()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab22edf7-5ee6-49dd-98f6-a9381a8f76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.cuda = torch.cuda.is_available()\n",
    "torch.cuda.set_device(args.device)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc98847-8512-4949-8c7c-0e953b2c4305",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/common/users/pv217/pritish_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29a2184c-1167-477c-993e-aa67d0925361",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset(data_path, \"train\", args.img_size, transform=transforms.Compose([ToTensor()]),shuffle=True,\n",
    "                rotate=True,vertical_flip=True, vertical_roll = True,\n",
    "                horizontal_flip = True, horizontal_roll= True, max_rotate_angle = 180\n",
    "               )\n",
    "valid = dataset(data_path, \"val\", args.img_size, transform=transforms.Compose([ToTensor()]))\n",
    "test = dataset(data_path, \"test\", args.img_size, transform=transforms.Compose([ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f82de8f-3484-470d-9078-7e985960b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train, batch_size=args.batch_size, shuffle=True, num_workers=16)\n",
    "validloader = DataLoader(valid, batch_size=args.batch_size, shuffle=False, num_workers=16)\n",
    "testloader = DataLoader(test, batch_size=args.batch_size, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f85bd3-36a1-4036-b099-e47add4fb42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.__getitem__(1)[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "633bf4f4-3801-4ae7-8a1a-9c170ce8a0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.__getitem__(1)[2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96349c6a-068c-41fb-853e-47b4cdfca395",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model == \"CNN_MLP\":\n",
    "    model = CNN_MLP(args)\n",
    "elif args.model == \"CNN_LSTM\":\n",
    "    model = CNN_LSTM(args)\n",
    "elif args.model == \"Resnet18_MLP\":\n",
    "    model = Resnet18_MLP(args)\n",
    "elif args.model == \"CNN_Logical\":\n",
    "    model = CNN_Logical(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47af98f3-16c1-4fff-99b0-2ea0ce015922",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume:\n",
    "    model.load_model(args.save, 0)\n",
    "    print('Loaded model')\n",
    "if args.cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5252445-b8cd-43a1-8090-86f6dfe77e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    loss_all = 0.0\n",
    "    acc_all = 0.0\n",
    "    counter = 0\n",
    "    for batch_idx, (image, target, meta_target) in enumerate(trainloader):\n",
    "        counter += 1\n",
    "        if args.cuda:\n",
    "            image = image.cuda()\n",
    "            target = target.cuda()\n",
    "            meta_target = meta_target.cuda()\n",
    "#             meta_structure = meta_structure.cuda()\n",
    "#             embedding = embedding.cuda()\n",
    "#             indicator = indicator.cuda()\n",
    "        loss, acc = model.train_(image, target, meta_target)\n",
    "        #print('Train: Epoch:{}, Batch:{}, Loss:{:.6f}, Acc:{:.4f}.'.format(epoch, batch_idx, loss, acc))\n",
    "        loss_all += loss\n",
    "        acc_all += acc\n",
    "    print(epoch)\n",
    "    if counter > 0:\n",
    "        print(\"Avg Training Loss: {:.6f}\".format(loss_all/float(counter)))\n",
    "    return loss_all/float(counter), acc_all/float(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dffc722-0e0c-4d50-a15b-a5b163edf7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    loss_all = 0.0\n",
    "    acc_all = 0.0\n",
    "    counter = 0\n",
    "    for batch_idx, (image, target, meta_target) in enumerate(validloader):\n",
    "        counter += 1\n",
    "        if args.cuda:\n",
    "            image = image.cuda()\n",
    "            target = target.cuda()\n",
    "            meta_target = meta_target.cuda()\n",
    "#             meta_structure = meta_structure.cuda()\n",
    "#             embedding = embedding.cuda()\n",
    "#             indicator = indicator.cuda()\n",
    "        loss, acc = model.validate_(image, target, meta_target)\n",
    "        # print('Validate: Epoch:{}, Batch:{}, Loss:{:.6f}, Acc:{:.4f}.'.format(epoch, batch_idx, loss, acc)) \n",
    "        loss_all += loss\n",
    "        acc_all += acc\n",
    "    if counter > 0:\n",
    "        print(\"Total Validation Loss: {:.6f}, Acc: {:.4f}\".format(loss_all/float(counter), acc_all/float(counter)))\n",
    "    return loss_all/float(counter), acc_all/float(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f27dde8-6eaa-496d-878f-21caddedfac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    accuracy = 0\n",
    "\n",
    "    acc_all = 0.0\n",
    "    counter = 0\n",
    "    for batch_idx, (image, target, meta_target) in enumerate(testloader):\n",
    "        counter += 1\n",
    "        if args.cuda:\n",
    "            image = image.cuda()\n",
    "            target = target.cuda()\n",
    "            meta_target = meta_target.cuda()\n",
    "#             meta_structure = meta_structure.cuda()\n",
    "#             embedding = embedding.cuda()\n",
    "#             indicator = indicator.cuda()\n",
    "        acc = model.test_(image, target, meta_target)\n",
    "        # print('Test: Epoch:{}, Batch:{}, Acc:{:.4f}.'.format(epoch, batch_idx, acc))  \n",
    "        acc_all += acc\n",
    "    if counter > 0:\n",
    "        print(\"Total Testing Acc: {:.4f}\".format(acc_all / float(counter)))\n",
    "    return acc_all/float(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7fb64f-b256-47e1-ae00-52852d3dd008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Avg Training Loss: 2.461007\n",
      "Total Validation Loss: 2.203331, Acc: 12.4857\n",
      "Total Testing Acc: 12.8853\n",
      "1\n",
      "Avg Training Loss: 2.189420\n",
      "Total Validation Loss: 2.141751, Acc: 12.0576\n",
      "Total Testing Acc: 12.4572\n",
      "2\n",
      "Avg Training Loss: 2.150948\n",
      "Total Validation Loss: 2.126423, Acc: 12.4715\n",
      "Total Testing Acc: 12.6998\n",
      "3\n",
      "Avg Training Loss: 2.135686\n",
      "Total Validation Loss: 2.112856, Acc: 12.8139\n",
      "Total Testing Acc: 12.5856\n",
      "4\n",
      "Avg Training Loss: 2.124443\n",
      "Total Validation Loss: 2.113324, Acc: 13.2063\n",
      "Total Testing Acc: 12.8995\n",
      "5\n",
      "Avg Training Loss: 2.115853\n",
      "Total Validation Loss: 2.109184, Acc: 13.0708\n",
      "Total Testing Acc: 13.1064\n",
      "6\n",
      "Avg Training Loss: 2.113154\n",
      "Total Validation Loss: 2.096251, Acc: 12.8853\n",
      "Total Testing Acc: 12.9352\n",
      "7\n",
      "Avg Training Loss: 2.110111\n",
      "Total Validation Loss: 2.095651, Acc: 13.3990\n",
      "Total Testing Acc: 13.4275\n",
      "8\n",
      "Avg Training Loss: 2.103269\n",
      "Total Validation Loss: 2.089283, Acc: 12.5999\n",
      "Total Testing Acc: 12.7497\n",
      "9\n",
      "Avg Training Loss: 2.105401\n",
      "Total Validation Loss: 2.089493, Acc: 12.5428\n",
      "Total Testing Acc: 12.7354\n",
      "10\n",
      "Avg Training Loss: 2.100157\n",
      "Total Validation Loss: 2.087511, Acc: 12.7854\n",
      "Total Testing Acc: 13.4703\n",
      "11\n",
      "Avg Training Loss: 2.096847\n",
      "Total Validation Loss: 2.086815, Acc: 13.7058\n",
      "Total Testing Acc: 13.0351\n",
      "12\n",
      "Avg Training Loss: 2.094952\n",
      "Total Validation Loss: 2.074436, Acc: 14.6475\n",
      "Total Testing Acc: 14.5762\n",
      "13\n",
      "Avg Training Loss: 2.080944\n",
      "Total Validation Loss: 2.054647, Acc: 14.8473\n",
      "Total Testing Acc: 15.0970\n",
      "14\n",
      "Avg Training Loss: 2.072284\n",
      "Total Validation Loss: 2.054209, Acc: 15.5037\n",
      "Total Testing Acc: 15.7320\n",
      "15\n",
      "Avg Training Loss: 2.064617\n",
      "Total Validation Loss: 2.039115, Acc: 15.7178\n",
      "Total Testing Acc: 15.9461\n",
      "16\n",
      "Avg Training Loss: 2.057596\n",
      "Total Validation Loss: 2.025346, Acc: 16.3385\n",
      "Total Testing Acc: 16.5739\n",
      "17\n",
      "Avg Training Loss: 2.049144\n",
      "Total Validation Loss: 2.009532, Acc: 16.7951\n",
      "Total Testing Acc: 16.8450\n",
      "18\n",
      "Avg Training Loss: 2.039384\n",
      "Total Validation Loss: 2.006194, Acc: 16.7951\n",
      "Total Testing Acc: 16.6809\n",
      "19\n",
      "Avg Training Loss: 2.029375\n",
      "Total Validation Loss: 1.990712, Acc: 17.1376\n",
      "Total Testing Acc: 17.4301\n",
      "20\n",
      "Avg Training Loss: 2.020743\n",
      "Total Validation Loss: 1.978617, Acc: 18.0365\n",
      "Total Testing Acc: 17.7297\n",
      "21\n",
      "Avg Training Loss: 2.016661\n",
      "Total Validation Loss: 1.970285, Acc: 18.3719\n",
      "Total Testing Acc: 18.2506\n",
      "22\n",
      "Avg Training Loss: 2.010458\n",
      "Total Validation Loss: 1.971666, Acc: 17.6869\n",
      "Total Testing Acc: 18.2149\n",
      "23\n",
      "Avg Training Loss: 2.004034\n",
      "Total Validation Loss: 1.954009, Acc: 17.9795\n",
      "Total Testing Acc: 18.4717\n",
      "24\n",
      "Avg Training Loss: 1.999803\n",
      "Total Validation Loss: 1.955137, Acc: 18.3933\n",
      "Total Testing Acc: 19.0782\n",
      "25\n",
      "Avg Training Loss: 1.988069\n",
      "Total Validation Loss: 1.940717, Acc: 18.8927\n",
      "Total Testing Acc: 19.0639\n",
      "26\n",
      "Avg Training Loss: 1.978943\n",
      "Total Validation Loss: 1.935292, Acc: 19.0925\n",
      "Total Testing Acc: 19.1709\n",
      "27\n",
      "Avg Training Loss: 1.979284\n",
      "Total Validation Loss: 1.929203, Acc: 19.1709\n",
      "Total Testing Acc: 20.0557\n",
      "28\n",
      "Avg Training Loss: 1.970511\n",
      "Total Validation Loss: 1.912774, Acc: 19.7203\n",
      "Total Testing Acc: 20.1627\n",
      "29\n",
      "Avg Training Loss: 1.965882\n",
      "Total Validation Loss: 1.915818, Acc: 20.2768\n",
      "Total Testing Acc: 19.7417\n",
      "30\n",
      "Avg Training Loss: 1.963237\n",
      "Total Validation Loss: 1.914317, Acc: 19.4991\n",
      "Total Testing Acc: 19.3921\n",
      "31\n",
      "Avg Training Loss: 1.957476\n",
      "Total Validation Loss: 1.905163, Acc: 20.2412\n",
      "Total Testing Acc: 19.7703\n",
      "32\n",
      "Avg Training Loss: 1.954361\n",
      "Total Validation Loss: 1.901843, Acc: 20.0128\n",
      "Total Testing Acc: 20.5123\n",
      "33\n",
      "Avg Training Loss: 1.951822\n",
      "Total Validation Loss: 1.891500, Acc: 20.1841\n",
      "Total Testing Acc: 20.2626\n",
      "34\n",
      "Avg Training Loss: 1.944416\n",
      "Total Validation Loss: 1.912885, Acc: 19.9130\n",
      "Total Testing Acc: 19.2138\n",
      "35\n",
      "Avg Training Loss: 1.939664\n",
      "Total Validation Loss: 1.890062, Acc: 20.6692\n",
      "Total Testing Acc: 20.2554\n",
      "36\n",
      "Avg Training Loss: 1.941697\n",
      "Total Validation Loss: 1.881999, Acc: 20.8833\n",
      "Total Testing Acc: 20.6835\n",
      "37\n",
      "Avg Training Loss: 1.934916\n",
      "Total Validation Loss: 1.885418, Acc: 21.0260\n",
      "Total Testing Acc: 21.0973\n",
      "38\n",
      "Avg Training Loss: 1.935088\n",
      "Total Validation Loss: 1.869420, Acc: 20.8619\n",
      "Total Testing Acc: 21.0759\n",
      "39\n",
      "Avg Training Loss: 1.931468\n",
      "Total Validation Loss: 1.875281, Acc: 20.8904\n",
      "Total Testing Acc: 20.9404\n",
      "40\n",
      "Avg Training Loss: 1.925881\n",
      "Total Validation Loss: 1.870791, Acc: 20.5551\n",
      "Total Testing Acc: 21.4755\n",
      "41\n",
      "Avg Training Loss: 1.922264\n",
      "Total Validation Loss: 1.874027, Acc: 21.2614\n",
      "Total Testing Acc: 20.8119\n",
      "42\n",
      "Avg Training Loss: 1.919437\n",
      "Total Validation Loss: 1.864802, Acc: 21.5539\n",
      "Total Testing Acc: 21.3114\n",
      "43\n",
      "Avg Training Loss: 1.917839\n",
      "Total Validation Loss: 1.852401, Acc: 21.8607\n",
      "Total Testing Acc: 21.6538\n",
      "44\n",
      "Avg Training Loss: 1.915350\n",
      "Total Validation Loss: 1.857268, Acc: 21.8679\n",
      "Total Testing Acc: 22.0177\n",
      "45\n",
      "Avg Training Loss: 1.916460\n",
      "Total Validation Loss: 1.864313, Acc: 21.8893\n",
      "Total Testing Acc: 21.5397\n",
      "46\n",
      "Avg Training Loss: 1.912744\n",
      "Total Validation Loss: 1.858941, Acc: 21.3898\n",
      "Total Testing Acc: 21.6966\n",
      "47\n",
      "Avg Training Loss: 1.907825\n",
      "Total Validation Loss: 1.844859, Acc: 21.8964\n",
      "Total Testing Acc: 21.7680\n",
      "48\n",
      "Avg Training Loss: 1.905053\n",
      "Total Validation Loss: 1.852457, Acc: 21.8179\n",
      "Total Testing Acc: 21.0331\n",
      "49\n",
      "Avg Training Loss: 1.903396\n",
      "Total Validation Loss: 1.844748, Acc: 22.0676\n",
      "Total Testing Acc: 21.8679\n",
      "50\n",
      "Avg Training Loss: 1.902143\n",
      "Total Validation Loss: 1.839774, Acc: 22.1318\n",
      "Total Testing Acc: 21.3256\n",
      "51\n",
      "Avg Training Loss: 1.902235\n",
      "Total Validation Loss: 1.845941, Acc: 22.2531\n",
      "Total Testing Acc: 21.8964\n",
      "52\n",
      "Avg Training Loss: 1.896186\n",
      "Total Validation Loss: 1.841151, Acc: 22.5742\n",
      "Total Testing Acc: 22.2888\n",
      "53\n",
      "Avg Training Loss: 1.894188\n",
      "Total Validation Loss: 1.822313, Acc: 22.6812\n",
      "Total Testing Acc: 22.4886\n",
      "54\n",
      "Avg Training Loss: 1.891552\n",
      "Total Validation Loss: 1.834087, Acc: 22.6527\n",
      "Total Testing Acc: 22.9309\n",
      "55\n",
      "Avg Training Loss: 1.888334\n",
      "Total Validation Loss: 1.819792, Acc: 22.7454\n",
      "Total Testing Acc: 22.5528\n",
      "56\n",
      "Avg Training Loss: 1.883857\n",
      "Total Validation Loss: 1.824493, Acc: 22.7954\n",
      "Total Testing Acc: 22.8239\n",
      "57\n",
      "Avg Training Loss: 1.881576\n",
      "Total Validation Loss: 1.812970, Acc: 23.5303\n",
      "Total Testing Acc: 22.9309\n",
      "58\n",
      "Avg Training Loss: 1.879041\n",
      "Total Validation Loss: 1.810267, Acc: 22.8525\n",
      "Total Testing Acc: 22.6527\n",
      "59\n",
      "Avg Training Loss: 1.879445\n",
      "Total Validation Loss: 1.801912, Acc: 23.2449\n",
      "Total Testing Acc: 23.0237\n",
      "60\n",
      "Avg Training Loss: 1.876311\n",
      "Total Validation Loss: 1.811261, Acc: 22.8311\n",
      "Total Testing Acc: 23.2449\n",
      "61\n",
      "Avg Training Loss: 1.872056\n",
      "Total Validation Loss: 1.808294, Acc: 23.2377\n",
      "Total Testing Acc: 23.5659\n",
      "62\n",
      "Avg Training Loss: 1.871166\n",
      "Total Validation Loss: 1.800029, Acc: 23.3091\n",
      "Total Testing Acc: 24.1866\n",
      "63\n",
      "Avg Training Loss: 1.867487\n",
      "Total Validation Loss: 1.806329, Acc: 23.1307\n"
     ]
    }
   ],
   "source": [
    "epoch_lst = []\n",
    "train_loss_lst = []\n",
    "train_acc_lst = []\n",
    "val_loss_lst = []\n",
    "val_acc_lst = []\n",
    "test_acc_lst = []\n",
    "\n",
    "for epoch in range(0, args.epochs):\n",
    "    train_loss, train_acc = train(epoch)\n",
    "    val_loss, val_acc = validate(epoch)\n",
    "    test_acc = test(epoch)\n",
    "    epoch_lst.append(epoch)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    train_acc_lst.append(train_acc)\n",
    "    val_loss_lst.append(val_loss)\n",
    "    val_acc_lst.append(val_acc)\n",
    "    test_acc_lst.append(test_acc)\n",
    "    model.save_model(args.save, epoch, val_acc, val_loss)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981b43e-d016-4b3c-abf5-9aba977fbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa1fb4-d13e-4ea4-8c95-d014d6d983a6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_stats = pd.DataFrame({'epoch':epoch_lst,\n",
    " 'training_loss':train_loss_lst,\n",
    " 'training_accuracy':train_acc_lst,\n",
    " 'validation_loss':val_loss_lst,\n",
    " 'validation_accuracy':val_acc_lst,\n",
    " 'test_accuracy':test_acc_lst\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d45854-ae30-46b6-aaed-dd29313f7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_stats = training_stats.set_index('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a821e0c9-cb8c-40e1-93aa-c35de2a4cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(15,8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bef803-a49a-4627-be6b-bfc15cd80fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=training_stats[['training_loss','validation_loss']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7daa0-4b66-41dc-bf12-d5d0d3ca932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=training_stats[['training_accuracy','validation_accuracy','test_accuracy']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a0a2a2-7e33-404b-8564-10477d95834c",
   "metadata": {},
   "source": [
    "#### Checking Model performance on each configuration  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375fb8aa-50cd-4549-8ff1-4303f97277ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    accuracy = 0\n",
    "    epoch = 1\n",
    "    loss_all = 0.0\n",
    "    acc_all = 0.0\n",
    "    counter = 0\n",
    "    for batch_idx, (image, target, meta_target) in enumerate(validloader):\n",
    "        counter += 1\n",
    "#         print(counter)\n",
    "        if args.cuda:\n",
    "            image = image.cuda()\n",
    "            target = target.cuda()\n",
    "            meta_target = meta_target.cuda()\n",
    "#             meta_structure = meta_structure.cuda()\n",
    "        loss, acc = model.validate_(image, target, meta_target)\n",
    "#         print('Validate: Epoch:{}, Batch:{}, Loss:{:.6f}, Acc:{:.4f}.'.format(epoch, batch_idx, loss, acc)) \n",
    "        loss_all += loss\n",
    "        acc_all += acc\n",
    "#         print(counter)\n",
    "    if counter >0:\n",
    "        print(\"Total Validation Loss: {:.6f}, Acc: {:.4f}\".format(loss_all/float(counter), acc_all/float(counter)))\n",
    "    return  acc_all/float(counter)\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    accuracy = 0\n",
    "    epoch = 1\n",
    "    acc_all = 0.0\n",
    "    counter = 0\n",
    "    for batch_idx, (image, target, meta_target) in enumerate(testloader):\n",
    "        counter += 1\n",
    "        if args.cuda:\n",
    "            image = image.cuda()\n",
    "            target = target.cuda()\n",
    "            meta_target = meta_target.cuda()\n",
    "#             meta_structure = meta_structure.cuda()\n",
    "#             embedding = embedding.cuda()\n",
    "#             indicator = indicator.cuda()\n",
    "        acc = model.test_(image, target, meta_target)\n",
    "        # print('Test: Epoch:{}, Batch:{}, Acc:{:.4f}.'.format(epoch, batch_idx, acc))  \n",
    "        acc_all += acc\n",
    "    if counter > 0:\n",
    "        print(\"Total Testing Acc: {:.4f}\".format(acc_all / float(counter)))\n",
    "    return acc_all/float(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0001510-7fa7-4a73-bef4-66cbe7966ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_lst = []\n",
    "config_val_acc_list = []\n",
    "config_test_acc_list = []\n",
    "for i in ['/center_single/','/distribute_four/','/distribute_nine/',\n",
    "          '/in_center_single_out_center_single/','/in_distribute_four_out_center_single/', \n",
    "          '/left_center_single_right_center_single/','/up_center_single_down_center_single/']:\n",
    "    valid_dt = dataset(data_path, \"val\", args.img_size, transform=transforms.Compose([ToTensor()]))\n",
    "    test_dt = dataset(data_path, \"test\", args.img_size, transform=transforms.Compose([ToTensor()]))\n",
    "    valid_dt.file_names = [x for x in valid_dt.file_names if i in x]\n",
    "    test_dt.file_names = [x for x in test_dt.file_names if i in x]\n",
    "    validloader = DataLoader(valid_dt, batch_size=args.batch_size, shuffle=False, num_workers=16)\n",
    "    testloader = DataLoader(test_dt, batch_size=args.batch_size, shuffle=False, num_workers=16)\n",
    "    config_lst.append(i[1:-1])\n",
    "    config_val_acc_list.append(validate())\n",
    "    config_test_acc_list.append(test())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934fcc54-31b9-462f-8623-63553a79de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'configuration':config_lst,'validation_accuracy':config_val_acc_list, 'test_accuracy':config_test_acc_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035dbc67-a4e7-45f2-8714-0aaed842bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"configuration\", y=\"test_accuracy\", data=pd.DataFrame({'configuration':config_lst,'validation_accuracy':config_val_acc_list, 'test_accuracy':config_test_acc_list}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34874350-ca7b-4ea2-aa75-068d32c385fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.s pd.DataFrame({'configuration':config_lst,'validation_accuracy':config_val_acc_list, 'test_accuracy':config_test_acc_list}).set_index('configuration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6314a35-6f47-4065-91bd-3f0d5f273ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['/center_single/','/distribute_four/','/in_distribute_four_out_center_single/', '/left_center_single_right_center_single/']:\n",
    "    train_dt = dataset(data_path, \"train\", args.img_size, transform=transforms.Compose([ToTensor()]))\n",
    "    valid_dt = dataset(data_path, \"val\", args.img_size, transform=transforms.Compose([ToTensor()]))\n",
    "    test_dt = dataset(data_path, \"test\", args.img_size, transform=transforms.Compose([ToTensor()]))\n",
    "    train_dt.file_names = [x for x in train_dt.file_names if i in x]\n",
    "    valid_dt.file_names = [x for x in valid_dt.file_names if i in x]\n",
    "    test_dt.file_names = [x for x in test_dt.file_names if i in x]\n",
    "    print(i,len(set(train_dt.file_names)),len(set(valid_dt.file_names)),len(set(test_dt.file_names)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809ca117-6ff6-4113-ad71-4fb0215a95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_stats.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb61255-de79-477b-b76d-59eefb34441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utl2 import dataset, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b480f1-b3bd-4196-87a3-748ff81143d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_t = '/common/home/pv217/Downloads/Data-Color/'\n",
    "test_dt = dataset(data_path, \"test\", args.img_size, transform=transforms.Compose([ToTensor()]),matrix=True)\n",
    "\n",
    "test_dt.file_names = [x for x in test_dt.file_names if '/center_single/' in x]\n",
    "testloader = DataLoader(test_dt, batch_size=args.batch_size, shuffle=False, num_workers=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5555af1e-7ce3-437a-924c-fe44d7cc6455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8970d1-9ce9-438a-bcf8-5615c01dd17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a7430e-21d5-4cd2-8cca-379d6c2d7f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ra_pairs_(model, image, target, ra_pair_matrix):\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "        pred = output[0].data.max(1)[1]\n",
    "        correct = pred.eq(target.data).cpu().sum().numpy()\n",
    "        ra_pair_matrix_correct = pred.eq(target.data).cpu().numpy().reshape(-1,1,1)*ra_pair_matrix.numpy()\n",
    "        accuracy = correct * 100.0 / target.size()[0]\n",
    "        return accuracy, ra_pair_matrix_correct.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a77ef-2772-41c9-80e9-0324ec4d4c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ra_pairs():\n",
    "#     model.eval()\n",
    "    accuracy = 0\n",
    "    epoch = 1\n",
    "    acc_all = 0.0\n",
    "    counter = 0\n",
    "    data_ra_pairs = np.zeros((4,5))\n",
    "    target_ra_pairs = np.zeros((4,5))\n",
    "    for batch_idx, (image, target, meta_target,rule_attribute_matrix) in enumerate(testloader):\n",
    "#         print(rule_attribute_matrix[10])\n",
    "#         a = meta_matrix\n",
    "        counter += 1\n",
    "        data_ra_pairs += rule_attribute_matrix.sum(axis=0).numpy()\n",
    "        \n",
    "        if args.cuda:\n",
    "            image = image.cuda()\n",
    "            target = target.cuda()\n",
    "            meta_target = meta_target.cuda()\n",
    "#             meta_structure = meta_structure.cuda()\n",
    "#             embedding = embedding.cuda()\n",
    "#             indicator = indicator.cuda()\n",
    "        \n",
    "        acc,acc_ra_pairs = test_ra_pairs_(model,image, target, rule_attribute_matrix)\n",
    "        # print('Test: Epoch:{}, Batch:{}, Acc:{:.4f}.'.format(epoch, batch_idx, acc))  \n",
    "        target_ra_pairs +=acc_ra_pairs\n",
    "        acc_all += acc\n",
    "    if counter > 0:\n",
    "        print(\"Total Testing Acc: {:.4f}\".format(acc_all / float(counter)))\n",
    "#     return rule_attribute_matrix\n",
    "    return acc_all/float(counter),data_ra_pairs,target_ra_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def1c30-2d48-47f6-9ae9-9e9e29230670",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, data_ra_matrix, accurate_ra_matrix = test_ra_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d12931c-c8fa-445d-a852-431a6408e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accurate_ra_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b6734-f56d-4aab-848c-66aab1e86621",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ra_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df097013-36e4-42bf-a735-84e444d3ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda8d512-24bd-4f48-b072-3d95bbad31cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "accuracy = accurate_ra_matrix/data_ra_matrix\n",
    "Mask = np.zeros(np.shape(accuracy))\n",
    "Mask[accuracy<=0.01] = 1\n",
    "_accuracy = accuracy*100.0\n",
    "midpoint = (_accuracy.max() - _accuracy.min()) / 2\n",
    "# plot the heatmap\n",
    "# plt.rcParams['font.size'] = 12\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "fig, ax = plt.subplots(1)\n",
    "sns.heatmap(_accuracy, \n",
    "            mask=Mask,\n",
    "            vmin=0.0, vmax=90.0,\n",
    "            #center = 45.0,\n",
    "            cmap=\"coolwarm\",\n",
    "            square=True,\n",
    "            robust=True,\n",
    "            annot=True, fmt=\".2f\",annot_kws={'size':12},\n",
    "            cbar=False,\n",
    "        yticklabels=['Constant', 'Progression', 'Arithmetic', 'Distribute Three'],\n",
    "        xticklabels=['Num', 'Pos', 'Type', 'Size', 'Color'])\n",
    "# plt.xlabel('Attributes', fontsize=16)\n",
    "# plt.ylabel('Rules', fontsize=16)\n",
    "plt.savefig(f\"heatmap_centersingle_i-raven.pdf\", bbox_inches='tight', pad_inches=0)\n",
    "# plt.text(5,12.3, \"I-RAVEN\", fontsize = 95, color='Black', fontstyle='italic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455228de-31f4-4abd-83b7-ec1647ba8fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f34c9f5-2722-44d3-928c-429e98f0ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_t = '/common/home/pv217/Downloads/Data-Color/'\n",
    "test_dt = dataset(data_path, \"test\", args.img_size, transform=transforms.Compose([ToTensor()]),matrix=True)\n",
    "\n",
    "# test_dt.file_names = [x for x in test_dt.file_names if '/center_single/' in x]\n",
    "testloader = DataLoader(test_dt, batch_size=args.batch_size, shuffle=False, num_workers=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c69ac6-a552-422b-aa22-7f9910db850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, data_ra_matrix, accurate_ra_matrix = test_ra_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550e360b-e17c-4cd4-a3b3-0dbbbc050346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "accuracy = accurate_ra_matrix/data_ra_matrix\n",
    "Mask = np.zeros(np.shape(accuracy))\n",
    "Mask[accuracy<=0.01] = 1\n",
    "_accuracy = accuracy*100.0\n",
    "midpoint = (_accuracy.max() - _accuracy.min()) / 2\n",
    "# plot the heatmap\n",
    "# plt.rcParams['font.size'] = 12\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "fig, ax = plt.subplots(1)\n",
    "sns.heatmap(_accuracy, \n",
    "            mask=Mask,\n",
    "            vmin=0.0, vmax=55.0,\n",
    "            #center = 45.0,\n",
    "            cmap=\"coolwarm\",\n",
    "            square=True,\n",
    "            robust=True,\n",
    "            annot=True, fmt=\".2f\",annot_kws={'size':12},\n",
    "            cbar=False,\n",
    "        yticklabels=['Constant', 'Progression', 'Arithmetic', 'Distribute Three'],\n",
    "        xticklabels=['Num', 'Pos', 'Type', 'Size', 'Color'])\n",
    "# plt.xlabel('Attributes', fontsize=16)\n",
    "# plt.ylabel('Rules', fontsize=16)\n",
    "plt.savefig(f\"heatmap_i-raven.pdf\", bbox_inches='tight', pad_inches=0)\n",
    "# plt.text(5,12.3, \"I-RAVEN\", fontsize = 95, color='Black', fontstyle='italic')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gln_new",
   "language": "python",
   "name": "gln_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

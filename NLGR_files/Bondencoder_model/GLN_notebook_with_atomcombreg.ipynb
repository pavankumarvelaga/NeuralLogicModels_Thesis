{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The OGB package is out of date. Your version is 1.3.1, while the latest version is 1.3.2.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ogb.graphproppred import PygGraphPropPredDataset,GraphPropPredDataset\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\n",
    "from IPython.display import SVG\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "   \n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.init import normal_ as normal_init\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SEED=42\n",
    "np.random.seed(DEFAULT_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_torch(d, gpu=True, requires_grad=True):\n",
    "    \"\"\"\n",
    "    numpy array转化为pytorch tensor，有gpu则放到gpu\n",
    "    :param d:\n",
    "    :param gpu: whether put tensor to gpu\n",
    "    :param requires_grad: whether the tensor requires grad\n",
    "    :return:\n",
    "    \n",
    "    Convert numpy array to pytorch tensor, if there is gpu then put into gpu\n",
    "    :param d:\n",
    "    :param gpu: whether put tensor to gpu\n",
    "    :param requires_grad: whether the tensor requires grad\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    t = torch.from_numpy(d)\n",
    "    if d.dtype is np.float:\n",
    "        t.requires_grad = requires_grad\n",
    "    if gpu:\n",
    "        t = tensor_to_gpu(t)\n",
    "    return t\n",
    "\n",
    "\n",
    "def tensor_to_gpu(t):\n",
    "    if torch.cuda.device_count() > 0:\n",
    "        t = t.cuda()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(self, vector1, vector2):\n",
    "        vector1, vector2 = self.uniform_size(vector1, vector2, train=False)\n",
    "        return (vector1 - vector2) ** 2\n",
    "\n",
    "def dot_product(self, vector1, vector2):\n",
    "    vector1, vector2 = self.uniform_size(vector1, vector2, train=False)\n",
    "    result = (vector1 * vector2).sum(dim=-1)\n",
    "    vector1_pow = vector1.pow(2).sum(dim=-1).pow(self.sim_alpha)\n",
    "    vector2_pow = vector2.pow(2).sum(dim=-1).pow(self.sim_alpha)\n",
    "    result = result / torch.clamp(vector1_pow * vector2_pow, min=1e-8)\n",
    "    return result\n",
    "\n",
    "def similarity(self, vector1, vector2, sigmoid=True):\n",
    "    result = F.cosine_similarity(vector1, vector2, dim=-1)\n",
    "    result = result * self.sim_scale\n",
    "    if sigmoid:\n",
    "        return result.sigmoid()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = self.similarity(result_vector, self.true).view([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datapreprocessing(object):\n",
    "    def __init__(self,dataset='ogbg-molhiv',path='./dataset/ogbg_molhiv/mapping/mol.csv.gz'):\n",
    "        self.dataset = dataset\n",
    "        self.path = path\n",
    "    \n",
    "    def read_data(self):\n",
    "        dataset = GraphPropPredDataset(name = self.dataset)\n",
    "        split_idx = dataset.get_idx_split()\n",
    "        self.train_idx, self.valid_idx, self.test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "        self.df = pd.read_csv(self.path)\n",
    "    \n",
    "    def atom_structure_from_smiles(self,smile_input):\n",
    "        mol = Chem.MolFromSmiles(smile_input)   \n",
    "        atom_stc_list = []\n",
    "        for i in mol.GetBonds():\n",
    "            atom_stc_list.append((i.GetBondType().name,i.GetBeginAtom().GetSymbol(),i.GetEndAtom().GetSymbol()))\n",
    "        return atom_stc_list\n",
    "    \n",
    "    def create_bond_list(self):\n",
    "        self.df['bond_list'] = self.df['smiles'].progress_apply(lambda x:self.atom_structure_from_smiles(x))\n",
    "    \n",
    "    \n",
    "    def create_atom_bond_labeler(self):\n",
    "        all_atoms = set()\n",
    "        all_bonds = set()\n",
    "        for j in self.df['bond_list'].values:\n",
    "            atom_lst = []\n",
    "            bond_lst = set()\n",
    "            for i in ([([i[1],i[2]],i[0]) for i in j]):\n",
    "                atom_lst.extend(i[0])\n",
    "                bond_lst.add(i[1])\n",
    "            mol_atoms = set(atom_lst)\n",
    "            all_atoms = all_atoms.union(mol_atoms)\n",
    "            all_bonds = all_bonds.union(bond_lst)\n",
    "        bond_dict = dict(zip(all_bonds,[i for i in range(1,len(all_bonds)+1)]))\n",
    "        atom_dict = dict(zip(all_atoms,[i for i in range(len(all_atoms)+1)]))\n",
    "        self.bond_dict = bond_dict\n",
    "        self.atom_dict = atom_dict\n",
    "        self.num_atoms = len(all_atoms)\n",
    "        \n",
    "    def logical_statement_creator(self,bond_list):\n",
    "        lst = []\n",
    "        for i in bond_list:\n",
    "            lst.append(str(self.atom_dict.get(i[1],0))+\"-\"+str(self.bond_dict.get(i[0],0))+\"-\"+str(self.atom_dict.get(i[2],0)))\n",
    "        return \"^\".join(lst)\n",
    "    \n",
    "    def create_logical_expression(self):\n",
    "        self.df['logical_expression']= self.df['bond_list'].progress_apply(lambda x: self.logical_statement_creator(x))\n",
    "        self.df['bond_len'] = self.df.bond_list.apply(lambda x: len(x))\n",
    "       \n",
    "    \n",
    "    \n",
    "    def data_splitter(self):\n",
    "        self.train_df, self.valid_df, self.test_df = self.df.iloc[self.train_idx] , self.df.iloc[self.valid_idx] , self.df.iloc[self.test_idx] \n",
    "        self.train_df = self.train_df[self.train_df['bond_len'] > 1]\n",
    "        self.valid_df = self.valid_df[self.valid_df['bond_len'] > 1]\n",
    "        self.test_df = self.test_df[self.test_df['bond_len'] > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 34965/41127 [00:18<00:03, 1713.47it/s]RDKit WARNING: [23:46:15] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [23:46:15] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|██████████| 41127/41127 [00:22<00:00, 1820.17it/s]\n",
      "100%|██████████| 41127/41127 [00:01<00:00, 20689.11it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = Datapreprocessing()\n",
    "dataset.read_data()\n",
    "dataset.create_bond_list()\n",
    "dataset.create_atom_bond_labeler()\n",
    "dataset.create_logical_expression()\n",
    "dataset.data_splitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, df,device='cuda'):\n",
    "        \n",
    "        # store the inputs and outputs\n",
    "        \n",
    "        \n",
    "        \n",
    "        df[\"input\"] =  df[\"logical_expression\"].apply(lambda x: np.array([i.split(\"-\") for i in x.split('^')]).astype(int))\n",
    "        self.X = df.input.values\n",
    "        self.y = df.HIV_active.values\n",
    "        \n",
    "#         self.X = self.X.to(device)\n",
    "#         self.y = self.y.to(device)\n",
    "         \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloder(object):\n",
    "    def __init__(self, dataset):\n",
    "        self.train_df = dataset.train_df\n",
    "        self.valid_df = dataset.valid_df\n",
    "        self.test_df = dataset.test_df\n",
    "    \n",
    "    \n",
    "        \n",
    "        # calculate split\n",
    "    #     train, test = dataset.get_splits()\n",
    "        # prepare data loaders\n",
    "    def preparedata(self):\n",
    "        \n",
    "        self.train = MolDataset(self.train_df)\n",
    "        self.valid = MolDataset(self.valid_df)\n",
    "        self.test = MolDataset(self.test_df)\n",
    "        \n",
    "#         self.train.X.to(device)  #train_dataset.train_data is a Tensor(input data)\n",
    "#         train_dataset.train_labels.to(CTX)\n",
    "        \n",
    "        \n",
    "        self.train_dl = DataLoader(self.train, batch_size=1, shuffle=True)\n",
    "        self.valid_dl = DataLoader(self.valid, batch_size=1, shuffle=False)\n",
    "        self.test_dl = DataLoader(self.test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloder = Dataloder(dataset)\n",
    "dataloder.preparedata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, n_atoms, emb_size=600, dropout=0.0, seed=2022, remove_double_not=False):\n",
    "        super(GLN, self).__init__()\n",
    "        self.n_atoms = n_atoms\n",
    "        self.emb_size = emb_size\n",
    "        self.dropout = dropout\n",
    "        self.seed = seed\n",
    "        # set pytorch and numpy seed\n",
    "        torch.manual_seed(self.seed)\n",
    "        torch.cuda.manual_seed(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "        # initialization of user and item embeddings\n",
    "        self.atom_embeddings = torch.nn.Embedding(self.n_atoms, self.emb_size)\n",
    "        # this is the true anchor vector that is fixed during the training of the model (for this reason it has the\n",
    "        # requires_grad parameter af False)\n",
    "        self.true_vector = torch.nn.Parameter(torch.from_numpy(\n",
    "            np.random.uniform(0, 0.1, size=self.emb_size).astype(np.float32)),\n",
    "            requires_grad=False)  # gradient is false to disable the training of the vector\n",
    "        # first layer of NOT network\n",
    "        self.not_layer_1 = torch.nn.Linear(self.emb_size, self.emb_size)\n",
    "        # second layer of NOT network (this network has two layers with the same number of neurons)\n",
    "        self.not_layer_2 = torch.nn.Linear(self.emb_size, self.emb_size)\n",
    "        # first layer of OR network: it takes two embeddings, so the input size is 2 * emb_size\n",
    "#         self.or_layer_1 = torch.nn.Linear(2 * self.emb_size, self.emb_size)\n",
    "#         # second layer of OR network\n",
    "#         self.or_layer_2 = torch.nn.Linear(self.emb_size, self.emb_size)\n",
    "#         # first layer of AND network (this network is not directly used, it is used only for the logical regularizers)\n",
    "        self.and_layer_1 = torch.nn.Linear(2 * self.emb_size, self.emb_size)\n",
    "        # second layer of AND network\n",
    "        self.and_layer_2 = torch.nn.Linear(self.emb_size, self.emb_size)\n",
    "        # first layer of encoder: it converts a pair of user-item vectors in an event vector (refer to the paper)\n",
    "        self.single_encoder_layer_1 = torch.nn.Linear(2 * self.emb_size, self.emb_size)\n",
    "        self.single_encoder_layer_2 = torch.nn.Linear(self.emb_size, self.emb_size)\n",
    "        \n",
    "        self.double_encoder_layer_1 = torch.nn.Linear(2 * self.emb_size, self.emb_size)\n",
    "        self.double_encoder_layer_2 = torch.nn.Linear(self.emb_size, self.emb_size)\n",
    "        \n",
    "        self.aromatic_encoder_layer_1 = torch.nn.Linear(2 * self.emb_size, self.emb_size)\n",
    "        self.aromatic_encoder_layer_2 = torch.nn.Linear(self.emb_size, self.emb_size)\n",
    "        \n",
    "        self.triple_encoder_layer_1 = torch.nn.Linear(2 * self.emb_size, self.emb_size)\n",
    "        self.triple_encoder_layer_2 = torch.nn.Linear(self.emb_size, self.emb_size)\n",
    "        \n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout_layer = torch.nn.Dropout(self.dropout)\n",
    "        # initialize the weights of the network\n",
    "        self.init_weights()\n",
    "        self.remove_double_not = remove_double_not\n",
    "        \n",
    "    \n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        It initializes all the weights of the neural architecture as reported in the paper.\n",
    "        \"\"\"\n",
    "        # not\n",
    "        normal_init(self.not_layer_1.weight, mean=0.0, std=0.01)\n",
    "        normal_init(self.not_layer_1.bias, mean=0.0, std=0.01)\n",
    "        normal_init(self.not_layer_2.weight, mean=0.0, std=0.01)\n",
    "        normal_init(self.not_layer_2.bias, mean=0.0, std=0.01)\n",
    "        # or\n",
    "#         normal_init(self.or_layer_1.weight, mean=0.0, std=0.01)\n",
    "#         normal_init(self.or_layer_1.bias, mean=0.0, std=0.01)\n",
    "#         normal_init(self.or_layer_2.weight, mean=0.0, std=0.01)\n",
    "#         normal_init(self.or_layer_2.bias, mean=0.0, std=0.01)\n",
    "        # and\n",
    "        normal_init(self.and_layer_1.weight, mean=0.0, std=0.01)\n",
    "        normal_init(self.and_layer_1.bias, mean=0.0, std=0.01)\n",
    "        normal_init(self.and_layer_2.weight, mean=0.0, std=0.01)\n",
    "        normal_init(self.and_layer_2.bias, mean=0.0, std=0.01)\n",
    "        \n",
    "        # Single bond encoder\n",
    "        normal_init(self.single_encoder_layer_1.weight, mean=0.0, std=0.01)\n",
    "        normal_init(self.single_encoder_layer_1.bias, mean=0.0, std=0.01)\n",
    "        normal_init(self.single_encoder_layer_2.weight, mean=0.0, std=0.01)\n",
    "        normal_init(self.single_encoder_layer_2.bias, mean=0.0, std=0.01)\n",
    "        \n",
    "        # Double bond encoder\n",
    "        normal_init(self.double_encoder_layer_1.weight, mean=0.0, std=0.01)\n",
    "        normal_init(self.double_encoder_layer_1.bias, mean=0.0, std=0.01)\n",
    "        normal_init(self.double_encoder_layer_2.weight, mean=0.0, std=0.01)\n",
    "        normal_init(self.double_encoder_layer_2.bias, mean=0.0, std=0.01)\n",
    "        \n",
    "        # encoder\n",
    "        normal_init(self.triple_encoder_layer_1.weight, mean=0.0, std=0.01)\n",
    "        normal_init(self.triple_encoder_layer_1.bias, mean=0.0, std=0.01)\n",
    "        normal_init(self.triple_encoder_layer_2.weight, mean=0.0, std=0.01)\n",
    "        normal_init(self.triple_encoder_layer_2.bias, mean=0.0, std=0.01)\n",
    "        \n",
    "        # Aromatic Bond encoder\n",
    "        normal_init(self.aromatic_encoder_layer_1.weight, mean=0.0, std=0.01)\n",
    "        normal_init(self.aromatic_encoder_layer_1.bias, mean=0.0, std=0.01)\n",
    "        normal_init(self.aromatic_encoder_layer_2.weight, mean=0.0, std=0.01)\n",
    "        normal_init(self.aromatic_encoder_layer_2.bias, mean=0.0, std=0.01)\n",
    "        \n",
    "        \n",
    "        # embeddings\n",
    "        normal_init(self.atom_embeddings.weight, mean=0.0, std=0.01)\n",
    "       \n",
    "    def logic_not(self, vector):\n",
    "\n",
    "        # ReLU is the activation function selected in the paper\n",
    "        vector = F.relu(self.not_layer_1(vector))\n",
    "        if self.training:\n",
    "            vector = self.dropout_layer(vector)\n",
    "        out = self.not_layer_2(vector)\n",
    "        return out\n",
    "\n",
    "#     def logic_or(self, vector1, vector2, dim=1):\n",
    "#         \"\"\"\n",
    "#         This represents the OR neural module. It takes in input two event vectors and returns a new event vector that is\n",
    "#         the logical disjunction of the two input event vectors.\n",
    "#         :param vector1: the first input event vector.\n",
    "#         :param vector2: the second input event vector.\n",
    "#         :param dim: the dimension for the concatenation of the two input event vectors.\n",
    "#         :return: the event vector that is the logical disjunction of the two input event vectors.\n",
    "#         \"\"\"\n",
    "#         vector = torch.cat((vector1, vector2), dim)\n",
    "#         vector = F.relu(self.or_layer_1(vector))\n",
    "#         if self.training:\n",
    "#             vector = self.dropout_layer(vector)\n",
    "#         out = self.or_layer_2(vector)\n",
    "#         return out\n",
    "\n",
    "    def logic_and(self, vector1, vector2, dim=1):\n",
    "        vector = torch.cat((vector1, vector2), dim)\n",
    "        vector = F.relu(self.and_layer_1(vector))\n",
    "        if self.training:\n",
    "            vector = self.dropout_layer(vector)\n",
    "        out = self.and_layer_2(vector)\n",
    "        return out\n",
    "\n",
    "    def single_bond_encoder(self, atom_atom_vector):\n",
    "        struct_vector = F.relu(self.single_encoder_layer_1(atom_atom_vector))\n",
    "        if self.training:\n",
    "            struct_vector = self.dropout_layer(struct_vector)\n",
    "        struct_vector = self.single_encoder_layer_2(struct_vector)\n",
    "        return struct_vector\n",
    "\n",
    "\n",
    "\n",
    "    def double_bond_encoder(self, atom_atom_vector):\n",
    "        struct_vector = F.relu(self.double_encoder_layer_1(atom_atom_vector))\n",
    "        if self.training:\n",
    "            struct_vector = self.dropout_layer(struct_vector)\n",
    "        struct_vector = self.double_encoder_layer_2(struct_vector)\n",
    "        return struct_vector\n",
    "\n",
    "    def triple_bond_encoder(self, atom_atom_vector):\n",
    "        struct_vector = F.relu(self.triple_encoder_layer_1(atom_atom_vector))\n",
    "        if self.training:\n",
    "            struct_vector = self.dropout_layer(struct_vector)\n",
    "        struct_vector = self.triple_encoder_layer_2(struct_vector)\n",
    "        return struct_vector\n",
    "\n",
    "    def aromatic_bond_encoder(self, atom_atom_vector):\n",
    "        struct_vector = F.relu(self.aromatic_encoder_layer_1(atom_atom_vector))\n",
    "        if self.training:\n",
    "            struct_vector = self.dropout_layer(struct_vector)\n",
    "        struct_vector = self.aromatic_encoder_layer_2(struct_vector)\n",
    "        return struct_vector\n",
    "    \n",
    "    def mse(self, vector1, vector2):\n",
    "        vector1, vector2 = self.uniform_size(vector1, vector2, train=False)\n",
    "        return (vector1 - vector2) ** 2\n",
    "\n",
    "    def dot_product(self, vector1, vector2):\n",
    "        vector1, vector2 = self.uniform_size(vector1, vector2, train=False)\n",
    "        result = (vector1 * vector2).sum(dim=-1)\n",
    "        vector1_pow = vector1.pow(2).sum(dim=-1).pow(self.sim_alpha)\n",
    "        vector2_pow = vector2.pow(2).sum(dim=-1).pow(self.sim_alpha)\n",
    "        result = result / torch.clamp(vector1_pow * vector2_pow, min=1e-8)\n",
    "        return result\n",
    "\n",
    "    def similarity(self, vector1, vector2, sigmoid=True):\n",
    "        result = F.cosine_similarity(vector1, vector2, dim=-1)\n",
    "        result = result * 10\n",
    "        if sigmoid:\n",
    "            return result.sigmoid()\n",
    "        return result\n",
    "\n",
    "    def forward(self, batch_data):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        atoms_list = batch_data.to(device)        \n",
    "        atoms_list = atoms_list[0]\n",
    "        \n",
    "        # {'DOUBLE': 1, 'AROMATIC': 2, 'SINGLE': 3, 'TRIPLE': 4}\n",
    "        \n",
    "        constraints = []\n",
    "        struct_list = []\n",
    "        atom_comb = []\n",
    "        \n",
    "        for i in atoms_list:\n",
    "            atom_left = self.atom_embeddings(i[0]).unsqueeze(0)\n",
    "            atom_right = self.atom_embeddings(i[2]).unsqueeze(0)\n",
    "            atomcomb = torch.cat([atom_left, atom_right], dim=1)\n",
    "            atom_comb.append(atomcomb)\n",
    "\n",
    "#             print(i,i[1],torch.tensor(3))\n",
    "            if i[1] == torch.tensor(3):              \n",
    "                struct_encoder = self.single_bond_encoder(atomcomb) \n",
    "            elif i[1] == torch.tensor(1):\n",
    "                struct_encoder = self.double_bond_encoder(atomcomb)\n",
    "            elif i[1] == torch.tensor(4):\n",
    "                struct_encoder = self.triple_bond_encoder(atomcomb)\n",
    "            else:\n",
    "                struct_encoder = self.aromatic_bond_encoder(atomcomb)\n",
    "            struct_list.append(struct_encoder)\n",
    "        \n",
    "        while len(struct_list) > 1:\n",
    "            op1 = struct_list[-1]\n",
    "            op2 = struct_list[-2]\n",
    "            struct_list = struct_list[:-2 or None]\n",
    "#             print(op1)\n",
    "            \n",
    "            and_res = self.logic_and(op1,op2)\n",
    "#             print(len(struct_list))\n",
    "            struct_list.append(and_res)\n",
    "            constraints.append(and_res)\n",
    "#         print(constraints)\n",
    "        if len(constraints) > 0:\n",
    "            constraints = torch.cat(constraints, dim=1)\n",
    "        constraints = constraints.view( constraints.size(1)//self.emb_size, self.emb_size)\n",
    "        \n",
    "        if len(atom_comb) > 0:\n",
    "            atom_comb = torch.cat(atom_comb, dim=1)\n",
    "        atom_comb = atom_comb.view( atom_comb.size(1)//(self.emb_size*2), self.emb_size*2)\n",
    "\n",
    "        \n",
    "        prediction = self.similarity(struct_list[0], self.true_vector).view([-1])\n",
    "        return prediction, constraints,atom_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLNTrainer(object):\n",
    "   \n",
    "    def __init__(self, net,dataloder, learning_rate=5e-6, l2_weight=1e-4, logic_reg_weight=0.1,atomcomb_reg_weight=0.01,weights = [1.0,10.0]):\n",
    "        self.network = net\n",
    "        self.lr = learning_rate\n",
    "        self.l2_weight = l2_weight\n",
    "        self.logic_reg_weight = logic_reg_weight\n",
    "        self.atomcomb_reg_weight = atomcomb_reg_weight\n",
    "        self.weights = torch.FloatTensor(weights) \n",
    "        self.optimizer = optim.Adam(self.network.parameters(), lr=self.lr, weight_decay=self.l2_weight)\n",
    "        self.dl = dataloder\n",
    "       \n",
    "    def logic_reg_loss(self, constraints):\n",
    "        \"\"\"\n",
    "        It computes the regularization part of the loss function.\n",
    "        :param constraints: see loss_function()\n",
    "        :return: the regularization loss for the batch intermediate event vectors given in input.\n",
    "        \"\"\"\n",
    "        false_vector = self.network.logic_not(self.network.true_vector)  # we compute the representation\n",
    "        \n",
    "        # here, we maximize the similarity between not not true and true\n",
    "        r_not_not_true = (1 - F.cosine_similarity(\n",
    "            self.network.logic_not(self.network.logic_not(self.network.true_vector)), self.network.true_vector,dim=0))\n",
    "\n",
    "#         here, we maximize the similarity between not true and false\n",
    "        r_not_true = (1 - F.cosine_similarity(self.network.logic_not(self.network.true_vector), false_vector, dim=0))\n",
    "\n",
    " \n",
    "        # here, we maximize the similarity between x AND True and x\n",
    "        r_and_true = (1 - F.cosine_similarity(\n",
    "            self.network.logic_and(constraints, self.network.true_vector.expand_as(constraints)), constraints)).mean()\n",
    "\n",
    "        # here, we maximize the similarity between x AND False and False\n",
    "        r_and_false = (1 - F.cosine_similarity(\n",
    "            self.network.logic_and(constraints, false_vector.expand_as(constraints)),\n",
    "            false_vector.expand_as(constraints))).mean()\n",
    "\n",
    "        # here, we maximize the similarity between x AND x and x\n",
    "        r_and_self = (1 - F.cosine_similarity(self.network.logic_and(constraints, constraints), constraints)).mean()\n",
    "\n",
    "        # here, we maximize the similarity between x AND not x and False\n",
    "        r_and_not_self = (1 - F.cosine_similarity(\n",
    "            self.network.logic_and(constraints, self.network.logic_not(constraints)),\n",
    "            false_vector.expand_as(constraints))).mean()\n",
    "\n",
    "        # same rule as before, but we flipped operands\n",
    "        r_and_not_self_inverse = (1 - F.cosine_similarity(\n",
    "            self.network.logic_and(self.network.logic_not(constraints), constraints),\n",
    "            false_vector.expand_as(constraints))).mean()\n",
    "\n",
    "        # True/False rule\n",
    "\n",
    "        # here, we minimize the similarity between True and False\n",
    "        true_false = 1 + F.cosine_similarity(self.network.true_vector, false_vector, dim=0)\n",
    "\n",
    "        r_loss = r_not_not_true + r_not_true + r_and_true + r_and_false + r_and_self + r_and_not_self + r_and_not_self_inverse\n",
    "\n",
    "        return r_loss\n",
    "\n",
    "    \n",
    "    def atomcombination_reg_loss(self, atoms_combs):\n",
    "        \"\"\"\n",
    "        It computes the regularization part of the loss function.\n",
    "        :param constraints: see loss_function()\n",
    "        :return: the regularization loss for the batch intermediate event vectors given in input.\n",
    "        \"\"\"\n",
    "        \n",
    "        # here, we maximize the similarity between not not true and true\n",
    "        \n",
    "        reverse_atom_combs = torch.cat((atoms_combs[:, self.network.emb_size:],atoms_combs[:, :self.network.emb_size]), 1)\n",
    "        single_bond_loss = (1 - F.cosine_similarity(self.network.single_bond_encoder(atoms_combs), self.network.single_bond_encoder(reverse_atom_combs))).mean()\n",
    "\n",
    "#         here, we maximize the similarity between not true and false\n",
    "        double_bond_losss = (1 - F.cosine_similarity(self.network.double_bond_encoder(atoms_combs), self.network.double_bond_encoder(reverse_atom_combs))).mean()\n",
    "\n",
    " \n",
    "        # here, we maximize the similarity between x AND True and x\n",
    "        aromatic_bond_loss = (1 - F.cosine_similarity(self.network.aromatic_bond_encoder(atoms_combs), self.network.aromatic_bond_encoder(reverse_atom_combs))).mean()\n",
    "\n",
    "        # here, we maximize the similarity between x AND False and False\n",
    "        tripple_bond_loss = (1 - F.cosine_similarity(self.network.triple_bond_encoder(atoms_combs), self.network.triple_bond_encoder(reverse_atom_combs))).mean()\n",
    "\n",
    "        \n",
    "        ac_loss = single_bond_loss + double_bond_losss + aromatic_bond_loss + tripple_bond_loss\n",
    "        \n",
    "        return ac_loss\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def BCELoss_class_weighted(self,predicton, target,weights):\n",
    "        input = torch.clamp(predicton,min=1e-7,max=1-1e-7)\n",
    "        bce = - weights[1] * target * torch.log(predicton) - (1 - target) * weights[0] * torch.log(1 - predicton)\n",
    "        return torch.mean(bce)\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "    def loss_function(self, prediction, label, logic_constraints,atoms_combs):\n",
    "        \"\"\"\n",
    "        This method computes the loss function for a single batch. It takes as inputs the predictions for positive\n",
    "        and negative logical expressions and a tensor containing the intermediate event vectors obtained while building\n",
    "        the logical expressions of the batch. The loss is computed as reported in the paper.\n",
    "        :param positive_preds: predictions for positive logical expressions.\n",
    "        :param negative_preds: predictions for negative logical expressions.\n",
    "        :param constraints: tensor containing the intermediate event vectors obtained while building the logical\n",
    "        expressions of the batch.\n",
    "        :return the partial loss function for the given batch.\n",
    "        \"\"\"\n",
    "        # here, implement loss function\n",
    "        \n",
    "#         print(type(prediction),type(label))\n",
    "#         weights = torch.FloatTensor([1.0, 10.0]) \n",
    "        \n",
    "        loss = torch.nn.BCELoss(reduction='sum')(prediction.to(torch.float64), label.to(torch.float64))\n",
    "#         loss = self.BCELoss_class_weighted(prediction.to(torch.float64), label.to(torch.float64),self.weights)\n",
    "        \n",
    "        \n",
    "        logic_reg_loss = self.logic_reg_loss(logic_constraints)\n",
    "        atomcombination_reg_loss = self.atomcombination_reg_loss(atoms_combs)\n",
    "\n",
    "        return loss + self.logic_reg_weight * logic_reg_loss + self.atomcomb_reg_weight * atomcombination_reg_loss\n",
    "\n",
    "    def train(self,\n",
    "              train_data = dataloder.train_dl,\n",
    "              valid_data=None,\n",
    "              valid_metric='auc_roc',\n",
    "              num_epochs=20,\n",
    "              at_least=20,\n",
    "              early_stop=5,\n",
    "              save_path=\"../saved_models/best_gln_model.json\",\n",
    "              verbose=1):\n",
    "        \n",
    "        best_val = 0.0\n",
    "        early_stop_counter = 0\n",
    "        early_stop_flag = False\n",
    "        if early_stop > 1:  # it means that the parameter is meaningful\n",
    "            early_stop_flag = True\n",
    "        try:\n",
    "            for epoch in range(1, num_epochs + 1):\n",
    "                print(f'Epoch:{epoch}')\n",
    "                self.train_epoch(epoch, train_data, verbose)\n",
    "#                 print(\"Now Model is Evaluating\")\n",
    "                val_lst = self.evaluate_model()\n",
    "                train_lst = self.evaluate_model(eval_data='Train')\n",
    "                print(f\"Train AUC_ROC: {train_lst[1]} , Train Loss: {train_lst[2]}, Validation AUC_ROC: {val_lst[1]} , Validation Loss: {val_lst[2]}\")\n",
    "                if valid_data is not None:\n",
    "                    assert valid_metric is not None, \\\n",
    "                                \"In case of validation 'valid_metric' must be provided\"\n",
    "                    valid_res = valid_func(self, valid_data, valid_metric)\n",
    "                    mu_val = np.mean(valid_res)\n",
    "                    std_err_val = np.std(valid_res) / np.sqrt(len(valid_res))\n",
    "                    logger.info('| epoch %d | %s %.3f (%.4f) |',\n",
    "                                epoch, valid_metric, mu_val, std_err_val)\n",
    "                    if mu_val > best_val:\n",
    "                        best_val = mu_val\n",
    "                        self.save_model(save_path, epoch)  # save model if an improved validation score has been\n",
    "                        # obtained\n",
    "                        early_stop_counter = 0  # we have reached a new validation best value, so we put the early stop\n",
    "                        # counter to zero\n",
    "                    else:\n",
    "                        # if we did not have obtained an improved validation metric, we have to increase the early\n",
    "                        # stopping counter\n",
    "                        if epoch >= at_least and early_stop_flag:  # we have to train for at least 20 epochs, they said that in the paper\n",
    "                            early_stop_counter += 1\n",
    "                            if early_stop_counter == early_stop:\n",
    "                                logger.info('Traing stopped at epoch %d due to early stopping', epoch)\n",
    "                                break\n",
    "        except KeyboardInterrupt:\n",
    "            logger.warning('Handled KeyboardInterrupt: exiting from training early')\n",
    "\n",
    "\n",
    "    def train_epoch(self, epoch, train_loader, verbose=1):\n",
    "        \"\"\"\n",
    "        This method performs the training of a single epoch.\n",
    "        :param epoch: id of the epoch.\n",
    "        :param train_loader: the DataLoader that loads the training set.\n",
    "        :param verbose: see train() method.\n",
    "        \"\"\"\n",
    "        self.network.train()  # set the network in train mode\n",
    "        train_loss = 0\n",
    "        partial_loss = 0\n",
    "        epoch_start_time = time.time()\n",
    "        start_time = time.time()\n",
    "        log_delay = max(10, len(train_loader) // 10**verbose)\n",
    "\n",
    "        for batch_idx, batch_data_f in enumerate(train_loader):\n",
    "            batch_data, label = batch_data_f\n",
    "            batch_data, label = batch_data.to(device), label.to(device) \n",
    "            label.to(device)\n",
    "            partial_loss += self.train_batch(batch_data,label)\n",
    "            if (batch_idx+1) % log_delay == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "#                 logger.info('| epoch %d | %d/%d batches | ms/batch %.2f | loss %.2f |',\n",
    "#                             epoch, (batch_idx+1), len(train_loader),\n",
    "#                             elapsed * 1000 / log_delay,\n",
    "#                             partial_loss / log_delay)\n",
    "                train_loss += partial_loss\n",
    "                partial_loss = 0.0\n",
    "                start_time = time.time()\n",
    "        total_loss = (train_loss + partial_loss) / len(train_loader)\n",
    "        time_diff = time.time() - epoch_start_time\n",
    "#         logger.info(\"| epoch %d | loss %.4f | total time: %.2fs |\", epoch, total_loss, time_diff)\n",
    "\n",
    "    def train_batch(self, batch_data,label):\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        prediction, constraints,atom_combs = self.network(batch_data)\n",
    "        loss = self.loss_function(prediction, label, constraints,atom_combs)\n",
    "        loss.backward()\n",
    "#         print(loss)\n",
    "        # this gradient clipping leads to lower results, so I removed it\n",
    "        torch.nn.utils.clip_grad_value_(self.network.parameters(), 50)  # this has been inserted in the code provided\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def predict(self, batch_data):\n",
    "        self.network.eval()  # we have to set the network in evaluation mode\n",
    "        with torch.no_grad():\n",
    "            prediction, _ = self.network(batch_data)\n",
    "        return prediction\n",
    "    \n",
    "    def evaluate_model(self,eval_data='Val'):\n",
    "        self.network.eval()\n",
    "        \n",
    "        if eval_data=='Val':\n",
    "            dl = self.dl.valid_dl\n",
    "        else:\n",
    "            dl = self.dl.train_dl\n",
    "        predictions, actuals,probs = list(), list(),list()\n",
    "        \n",
    "        for i, (inputs, targets) in enumerate(dl):\n",
    "            # evaluate the model on the test set\n",
    "            with torch.no_grad():\n",
    "                yhat,_,_ = self.network(inputs)\n",
    "            # retrieve numpy array\n",
    "            yhat = yhat.cpu().detach().numpy()\n",
    "            actual = targets.numpy()\n",
    "            actual = actual.reshape((len(actual), 1))\n",
    "            probs.append(yhat)\n",
    "            yhat = yhat.round()\n",
    "\n",
    "            # store\n",
    "            predictions.append(yhat)\n",
    "            actuals.append(actual)\n",
    "        predictions, actuals,probs =  np.vstack(predictions), np.vstack(actuals),np.vstack(probs)\n",
    "        # calculate accuracy\n",
    "        acc = accuracy_score(actuals, predictions)\n",
    "        auc = roc_auc_score(actuals,probs)\n",
    "        loss = log_loss(actuals,probs)\n",
    "        return [acc,auc,loss]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#     def save_model(self, filepath, cur_epoch):\n",
    "#         \"\"\"Save the model into the given file.\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         filepath : :obj:`str`\n",
    "#             String representing the path to the file where to save the model.\n",
    "#         cur_epoch : :obj:`int`\n",
    "#             The current training epoch.\n",
    "#         \"\"\"\n",
    "#         logger.info(\"Saving model checkpoint to %s...\", filepath)\n",
    "#         torch.save({'epoch': cur_epoch,\n",
    "#                  'state_dict': self.network.state_dict(),\n",
    "#                  'optimizer': self.optimizer.state_dict()\n",
    "#                 }, filepath)\n",
    "#         logger.info(\"Model checkpoint saved!\")\n",
    "\n",
    "#     def load_model(self, filepath):\n",
    "#         \"\"\"Load the model from the given file.\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         filepath : :obj:`str`\n",
    "#             String representing the path to the file where the model is saved.\n",
    "#         Returns\n",
    "#         -------\n",
    "#         :obj:`dict`\n",
    "#             A dictionary that summarizes the state of the model when it has been saved.\n",
    "#             Note: not all the information about the model are stored in the saved 'checkpoint'.\n",
    "#         \"\"\"\n",
    "#         assert os.path.isfile(filepath), \"The checkpoint file %s does not exist.\" %filepath\n",
    "#         logger.info(\"Loading model checkpoint from %s...\", filepath)\n",
    "#         checkpoint = torch.load(filepath, map_location=torch.device('cpu'))\n",
    "#         self.network.load_state_dict(checkpoint['state_dict'])\n",
    "#         self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "#         logger.info(\"Model checkpoint loaded!\")\n",
    "#         return checkpoint\n",
    "\n",
    "#     def test(self, test_loader, test_metrics=['ndcg@5', 'ndcg@10', 'hit@5', 'hit@10'], n_times=10):\n",
    "#         \"\"\"\n",
    "#         This method performs the test of a trained NCR model.\n",
    "#         :param test_loader: this is the DataSampler that loads the test set interactions.\n",
    "#         :param test_metrics: this is a list containing the test metrics that have to be computed.\n",
    "#         :param n_times: this is the number of times that the evaluation has to be computed. Since the test loader\n",
    "#         generates 100 random negative items for each interaction in the test set, different random generations\n",
    "#         could lead to different test performances. The evaluation will be computed n_times times and then each metric\n",
    "#         will be averaged among these n_times evaluations.\n",
    "#         This method will log the value of each one of the metrics (plus std error) once this procedure has finished.\n",
    "#         \"\"\"\n",
    "#         metric_dict = {}\n",
    "#         for i in range(n_times):  # compute test metrics n_times times and take the mean since negative samples are\n",
    "#             # randomly generated\n",
    "#             evaluation_dict = logic_evaluate(self, test_loader, test_metrics)\n",
    "#             for metric in evaluation_dict:\n",
    "#                 if metric not in metric_dict:\n",
    "#                     metric_dict[metric] = {}\n",
    "#                 metric_mean = np.mean(evaluation_dict[metric])\n",
    "#                 metric_std_err_val = np.std(evaluation_dict[metric]) / np.sqrt(len(evaluation_dict[metric]))\n",
    "#                 if \"mean\" not in metric_dict[metric]:\n",
    "#                     metric_dict[metric][\"mean\"] = metric_mean\n",
    "#                     metric_dict[metric][\"std\"] = metric_std_err_val\n",
    "#                 else:\n",
    "#                     metric_dict[metric][\"mean\"] += metric_mean\n",
    "#                     metric_dict[metric][\"std\"] += metric_std_err_val\n",
    "\n",
    "#         for metric in metric_dict:\n",
    "#             logger.info('%s: %.3f (%.4f)', metric, metric_dict[metric][\"mean\"] / n_times,\n",
    "#                         metric_dict[metric][\"std\"] / n_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GLN(n_atoms= len(dataset.atom_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GLNTrainer(net,dataloder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\n",
      "Train AUC_ROC: 0.5641990294497241 , Train Loss: 0.16238132163362737, Validation AUC_ROC: 0.6353998260826964 , Validation Loss: 0.112359124034962\n",
      "Epoch:2\n",
      "Train AUC_ROC: 0.5842044280600192 , Train Loss: 0.15837479018784845, Validation AUC_ROC: 0.6222840730942583 , Validation Loss: 0.10378513479283329\n",
      "Epoch:3\n",
      "Train AUC_ROC: 0.5841297492493928 , Train Loss: 0.15953142444922097, Validation AUC_ROC: 0.5736484665882814 , Validation Loss: 0.09743743633238679\n",
      "Epoch:4\n",
      "Train AUC_ROC: 0.5871339725815601 , Train Loss: 0.15797168035137166, Validation AUC_ROC: 0.5862957451499118 , Validation Loss: 0.09744260797083265\n",
      "Epoch:5\n",
      "Train AUC_ROC: 0.5883756760181744 , Train Loss: 0.1580464816200151, Validation AUC_ROC: 0.5765128968253967 , Validation Loss: 0.09839903188795993\n",
      "Epoch:6\n",
      "Train AUC_ROC: 0.5930582181499935 , Train Loss: 0.15821773290606186, Validation AUC_ROC: 0.6684716710758377 , Validation Loss: 0.09656656378100757\n",
      "Epoch:7\n",
      "Train AUC_ROC: 0.6034164652333803 , Train Loss: 0.15735226391231125, Validation AUC_ROC: 0.6060849622770919 , Validation Loss: 0.09993083907303521\n",
      "Epoch:8\n",
      "Train AUC_ROC: 0.6004453456197385 , Train Loss: 0.15786183468626128, Validation AUC_ROC: 0.6229224843229473 , Validation Loss: 0.09628605761866652\n",
      "Epoch:9\n",
      "Train AUC_ROC: 0.6074250141181016 , Train Loss: 0.15778678154087694, Validation AUC_ROC: 0.6513172398589064 , Validation Loss: 0.09585805519135501\n",
      "Epoch:10\n",
      "Train AUC_ROC: 0.6024573801478782 , Train Loss: 0.15776685969900386, Validation AUC_ROC: 0.6625330687830688 , Validation Loss: 0.09665762449153005\n",
      "Epoch:11\n",
      "Train AUC_ROC: 0.60535715310994 , Train Loss: 0.15693472113963403, Validation AUC_ROC: 0.6559376837154615 , Validation Loss: 0.09720243894400647\n",
      "Epoch:12\n",
      "Train AUC_ROC: 0.6117970374747934 , Train Loss: 0.15621806783641556, Validation AUC_ROC: 0.6554891117969821 , Validation Loss: 0.09810865989397353\n",
      "Epoch:13\n",
      "Train AUC_ROC: 0.6169066855003713 , Train Loss: 0.15668374181441236, Validation AUC_ROC: 0.6649703605722123 , Validation Loss: 0.09506868063015947\n",
      "Epoch:14\n",
      "Train AUC_ROC: 0.6148163964986288 , Train Loss: 0.1558681213517445, Validation AUC_ROC: 0.6277251126788164 , Validation Loss: 0.09630637582044604\n",
      "Epoch:15\n",
      "Train AUC_ROC: 0.6124416180103094 , Train Loss: 0.15484855057506458, Validation AUC_ROC: 0.642583100627082 , Validation Loss: 0.09767689913094185\n",
      "Epoch:16\n",
      "Train AUC_ROC: 0.6104483076528108 , Train Loss: 0.15556193119572398, Validation AUC_ROC: 0.6749782603370567 , Validation Loss: 0.09358943342823339\n",
      "Epoch:17\n",
      "Train AUC_ROC: 0.6177198476516379 , Train Loss: 0.1539688566792193, Validation AUC_ROC: 0.6371849279835391 , Validation Loss: 0.09816954965883658\n",
      "Epoch:18\n",
      "Train AUC_ROC: 0.6250805100889574 , Train Loss: 0.1534689485908236, Validation AUC_ROC: 0.6580289780521262 , Validation Loss: 0.09750713352517014\n",
      "Epoch:19\n",
      "Train AUC_ROC: 0.6181962951312747 , Train Loss: 0.15578130568384213, Validation AUC_ROC: 0.6073525989613953 , Validation Loss: 0.09323786586730697\n",
      "Epoch:20\n",
      "Train AUC_ROC: 0.6267597003763596 , Train Loss: 0.15255736912001375, Validation AUC_ROC: 0.58530061973349 , Validation Loss: 0.09834654573890057\n"
     ]
    }
   ],
   "source": [
    "# CUDA_LAUNCH_BLOCKING=1\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\n",
      "Train AUC_ROC: 0.6304708668821941 , Train Loss: 0.1529601733996005, Validation AUC_ROC: 0.645926722026259 , Validation Loss: 0.09527358364014042\n",
      "Epoch:2\n",
      "Train AUC_ROC: 0.6318419349857836 , Train Loss: 0.152172505059227, Validation AUC_ROC: 0.5870351998824221 , Validation Loss: 0.09720908226006035\n",
      "Epoch:3\n",
      "Train AUC_ROC: 0.636379335959143 , Train Loss: 0.15222266808736148, Validation AUC_ROC: 0.6251837154614932 , Validation Loss: 0.09556627072769322\n",
      "Epoch:4\n",
      "Train AUC_ROC: 0.6445212871648515 , Train Loss: 0.15229206396176345, Validation AUC_ROC: 0.6100715877914952 , Validation Loss: 0.09597197267716652\n",
      "Epoch:5\n",
      "Train AUC_ROC: 0.6399335577738963 , Train Loss: 0.15181115076592477, Validation AUC_ROC: 0.6457292279051539 , Validation Loss: 0.09670368905278608\n",
      "Epoch:6\n",
      "Train AUC_ROC: 0.6440108901109312 , Train Loss: 0.15170236883837773, Validation AUC_ROC: 0.6075271286498138 , Validation Loss: 0.09782279031393099\n",
      "Epoch:7\n",
      "Train AUC_ROC: 0.6470905227655156 , Train Loss: 0.15117218063572366, Validation AUC_ROC: 0.5842993704683519 , Validation Loss: 0.0988844395491754\n",
      "Epoch:8\n",
      "Train AUC_ROC: 0.6526445654639043 , Train Loss: 0.14985148209711088, Validation AUC_ROC: 0.6110713060944543 , Validation Loss: 0.0943670941206769\n",
      "Epoch:9\n",
      "Train AUC_ROC: 0.6351863076765972 , Train Loss: 0.15323021901663458, Validation AUC_ROC: 0.6400233318636096 , Validation Loss: 0.09691028135386902\n",
      "Epoch:10\n",
      "Train AUC_ROC: 0.6529870729658758 , Train Loss: 0.15166132537581953, Validation AUC_ROC: 0.6188164437585734 , Validation Loss: 0.09321350985519822\n",
      "Epoch:11\n",
      "Train AUC_ROC: 0.6432485946491063 , Train Loss: 0.1504922927381998, Validation AUC_ROC: 0.6206122623946698 , Validation Loss: 0.0970834369690006\n",
      "Epoch:12\n",
      "Train AUC_ROC: 0.6493530715739562 , Train Loss: 0.15259724496285298, Validation AUC_ROC: 0.6562147878698804 , Validation Loss: 0.09271828457588588\n",
      "Epoch:13\n",
      "Train AUC_ROC: 0.6439487453447175 , Train Loss: 0.14999404159470248, Validation AUC_ROC: 0.5991542964922595 , Validation Loss: 0.09369467127884344\n",
      "Epoch:14\n",
      "Train AUC_ROC: 0.6610518975056585 , Train Loss: 0.14920790653461272, Validation AUC_ROC: 0.5790558250048992 , Validation Loss: 0.09850988211444224\n",
      "Epoch:15\n",
      "Train AUC_ROC: 0.6601000021940985 , Train Loss: 0.1486626628120806, Validation AUC_ROC: 0.6021993802665099 , Validation Loss: 0.09421125072247713\n",
      "Epoch:16\n",
      "Train AUC_ROC: 0.6596654245744782 , Train Loss: 0.15046804699243493, Validation AUC_ROC: 0.6138500024495395 , Validation Loss: 0.09212823907332755\n",
      "Epoch:17\n",
      "Train AUC_ROC: 0.6627107231748894 , Train Loss: 0.14809901602745576, Validation AUC_ROC: 0.5814931167940427 , Validation Loss: 0.09509096201237517\n",
      "Epoch:18\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GLN(\n",
       "  (atom_embeddings): Embedding(53, 600)\n",
       "  (not_layer_1): Linear(in_features=600, out_features=600, bias=True)\n",
       "  (not_layer_2): Linear(in_features=600, out_features=600, bias=True)\n",
       "  (and_layer_1): Linear(in_features=1200, out_features=600, bias=True)\n",
       "  (and_layer_2): Linear(in_features=600, out_features=600, bias=True)\n",
       "  (single_encoder_layer_1): Linear(in_features=1200, out_features=600, bias=True)\n",
       "  (single_encoder_layer_2): Linear(in_features=600, out_features=600, bias=True)\n",
       "  (double_encoder_layer_1): Linear(in_features=1200, out_features=600, bias=True)\n",
       "  (double_encoder_layer_2): Linear(in_features=600, out_features=600, bias=True)\n",
       "  (aromatic_encoder_layer_1): Linear(in_features=1200, out_features=600, bias=True)\n",
       "  (aromatic_encoder_layer_2): Linear(in_features=600, out_features=600, bias=True)\n",
       "  (triple_encoder_layer_1): Linear(in_features=1200, out_features=600, bias=True)\n",
       "  (triple_encoder_layer_2): Linear(in_features=600, out_features=600, bias=True)\n",
       "  (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "predictions, actuals,probs = list(), list(),list()\n",
    "for i, (inputs, targets) in enumerate(dataloder.test_dl):\n",
    "    # evaluate the model on the test set\n",
    "    with torch.no_grad():\n",
    "        yhat,_,_ = net(inputs)\n",
    "    # retrieve numpy array\n",
    "    yhat = yhat.cpu().detach().numpy()\n",
    "    actual = targets.numpy()\n",
    "    actual = actual.reshape((len(actual), 1))\n",
    "    probs.append(yhat)\n",
    "    yhat = yhat.round()\n",
    "\n",
    "    # store\n",
    "    predictions.append(yhat)\n",
    "    actuals.append(actual)\n",
    "predictions, actuals,probs =  np.vstack(predictions), np.vstack(actuals),np.vstack(probs)\n",
    "# calculate accuracy\n",
    "acc = accuracy_score(actuals, predictions)\n",
    "auc = roc_auc_score(actuals,probs)\n",
    "loss = log_loss(actuals,probs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.603334363351938, 0.14315365084212947)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = dataset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    39684\n",
       "1     1443\n",
       "Name: HIV_active, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df['HIV_active'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = dict(all_df['bond_len'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 156 artists>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(dict_.keys(),dict_.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[\"bond_type_counter\"] =  all_df[\"logical_expression\"].apply(lambda x: dict(Counter(np.array([i.split(\"-\") for i in x.split('^')])[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[\"bond_type_counter_idf\"]  = all_df[\"bond_type_counter\"].apply(lambda x: str(x.get('1',0))+\"-\"+str(x.get('2',0))+\"-\"+str(x.get('3',0))+\"-\"+str(x.get('4',0)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4613"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(all_df[\"bond_type_counter_idf\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = dict(all_df['bond_type_counter_idf'].value_counts(normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'10-6-2-0': 221,\n",
    " '11-6-2-0': 219,\n",
    " '9-6-2-0': 217,\n",
    " '9-12-2-0': 209,\n",
    " '11-12-2-0': 191,\n",
    " '7-12-2-0': 190,\n",
    " '8-12-2-0': 189,\n",
    " '12-12-2-0': 186..}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.148e+03, 2.400e+02, 1.050e+02, 5.800e+01, 2.000e+01, 1.500e+01,\n",
       "        1.500e+01, 4.000e+00, 4.000e+00, 4.000e+00]),\n",
       " array([2.43149269e-05, 5.59243319e-04, 1.09417171e-03, 1.62910010e-03,\n",
       "        2.16402850e-03, 2.69895689e-03, 3.23388528e-03, 3.76881367e-03,\n",
       "        4.30374207e-03, 4.83867046e-03, 5.37359885e-03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dict_.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gln",
   "language": "python",
   "name": "gln"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
